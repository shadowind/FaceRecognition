{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Thisn notebook is used for train a face recongizer by loading images \n",
    "# and apply the model on live camera input \n",
    "# Version:\n",
    "# Python 3.5\n",
    "# openCV 3.1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "import time\n",
    "import numpy as np\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'3.1.0'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check version \n",
    "cv2.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Define system path and lookup files\n",
    "# Create the haar cascade\n",
    "faceCascade = cv2.CascadeClassifier('./data/haarcascade_frontalface_default.xml')\n",
    "train_img_folder = './Images/Train'\n",
    "test_img_folder = './Images/Test'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Give a predefined people id in dictionary, can be automated based on files different name\n",
    "#dict = {'Kai:1, 'Sherry':2}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# The following block substitue the previous block by getting the filenames in folders, which is person1.png. The\n",
    "# goal is to get the unique list of person, and give them an index since recognier only work with numpy array. It\n",
    "# has to be numeric\n",
    "\n",
    "files = os.listdir(train_img_folder)\n",
    "#print(files)\n",
    "r = re.compile('[A-z]+')\n",
    "name = []\n",
    "for file in files:\n",
    "    name.append(r.match(file).group(0))\n",
    "\n",
    "person = set(name)\n",
    "index = range(1,len(person)+1,1)\n",
    "dictionary = dict(zip(person,index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training sample size on: \n",
      "Kai is 5 \n",
      "Sun is 10\n"
     ]
    }
   ],
   "source": [
    "# Import training data and labels\n",
    "images = []\n",
    "labels = []\n",
    "for filename in os.listdir(train_img_folder):\n",
    "    #print(filename)\n",
    "    path = os.path.join(train_img_folder, filename)\n",
    "    img = cv2.imread(path,0)\n",
    "    imagenp = np.array(img, 'uint8')\n",
    "    label = re.match('[a-zA-Z]+',filename).group(0)\n",
    "    label = dictionary[str(label)]\n",
    "    faces = faceCascade.detectMultiScale(imagenp)\n",
    "    for (x, y, w, h) in faces:\n",
    "        images.append(imagenp[y: y + h, x: x + w])\n",
    "        labels.append(label)\n",
    "        \n",
    "Kai = labels.count(1)\n",
    "Sun = labels.count(2)\n",
    "print(\"Training sample size for: \\n{} is {} \\n{} is {}\".format(list(person)[0],Kai, list(person)[1],Sun))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "recognizer = cv2.face.createLBPHFaceRecognizer()\n",
    "#createFisherFaceRecognizer()\n",
    "#createEigenFaceRecognizer()\n",
    "\n",
    "recognizer.train(images,np.array(labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on built-in function createLBPHFaceRecognizer:\n",
      "\n",
      "createLBPHFaceRecognizer(...)\n",
      "    createLBPHFaceRecognizer([, radius[, neighbors[, grid_x[, grid_y[, threshold]]]]]) -> retval\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Find the documentation for a function\n",
    "# help(cv2.face.createLBPHFaceRecognizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kai\n"
     ]
    }
   ],
   "source": [
    "# Inverse dictionary lookup - Python\n",
    "name = [name for name, index in dictionary.items() if index == 1][0]\n",
    "print(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kai is Correctly Recognized with confidence 0.0%\n",
      "Sun is Correctly Recognized with confidence 0.0%\n"
     ]
    }
   ],
   "source": [
    "for filename in os.listdir(test_img_folder): \n",
    "    predict_image_path = os.path.join(test_img_folder, filename)\n",
    "    predict_img = cv2.imread(predict_image_path,0)\n",
    "    imagenp = np.array(predict_img, 'uint8')\n",
    "    faces = faceCascade.detectMultiScale(imagenp)\n",
    "    for (x, y, w, h) in faces:\n",
    "        #nbr_predicted = recognizer.predict(imagenp[y: y + h, x: x + w])\n",
    "        result = cv2.face.MinDistancePredictCollector()\n",
    "        recognizer.predict(imagenp[y: y + h, x: x + w],result, 0)\n",
    "        nbr_predicted = result.getLabel()\n",
    "        conf = result.getDist()   \n",
    "        name_pred = [name for name, index in dictionary.items() if index == nbr_predicted][0]\n",
    "        nbr_actual = re.match('[A-z]+',filename).group(0)\n",
    "        if nbr_actual == name_pred:\n",
    "            print(\"{} is Correctly Recognized with confidence {}%\".format(nbr_actual,round(conf,2)))\n",
    "        else: \n",
    "            print(\"{} is Incorrectly Recognized as {}\".format(nbr_actual, name_pred))\n",
    "        \n",
    "        #cv2.putText(frame,name_pred, (x,y),cv2.FONT_HERSHEY_SIMPLEX,0.5,(0,255,255),2,cv2.LINE_AA)\n",
    "        #cv2.imshow(\"Recognizing Face\", imagenp[y: y + h, x: x + w])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Read the image\n",
    "#image = cv2.imread('tom.jpg')\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "current_face = 1\n",
    "\n",
    "while(1):\n",
    "# take first frame of the video\n",
    "    ret,frame = cap.read()\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    imagenp = np.array(gray, 'uint8')\n",
    "    # Detect faces in the image\n",
    "    faces = faceCascade.detectMultiScale(\n",
    "        gray,\n",
    "        scaleFactor=1.1,\n",
    "        minNeighbors=5,\n",
    "        minSize=(30, 30)#,\n",
    "        #flags = cv2.CV_HAAR_SCALE_IMAGE\n",
    "    )\n",
    "    for (x, y, w, h) in faces:\n",
    "        result = cv2.face.MinDistancePredictCollector()\n",
    "        recognizer.predict(imagenp[y: y + h, x: x + w],result, 0)\n",
    "        nbr_predicted = result.getLabel()\n",
    "        conf = result.getDist()   \n",
    "        name_pred = [name for name, index in dictionary.items() if index == nbr_predicted][0]\n",
    "        \n",
    "        img = cv2.rectangle(frame, (x,y),(x+w,y+h),(255,0,0),2)\n",
    "        cv2.putText(frame, name_pred, (x,y),cv2.FONT_HERSHEY_SIMPLEX,0.5,(0,166,255),2,cv2.LINE_AA)\n",
    "        roi_gray= gray[y:y+h, x:x+w]\n",
    "        roi_color = frame[y:y+h, x:x+w]\n",
    "        #cv2.rectangle(frame, (x, y), (x+w, y+h), (0, 255, 0), 2)\n",
    "        #eyes = eyecascade.detectMultiScale(roi_gray)\n",
    "        #for (ex,ey,ew,eh) in eyes:\n",
    "        #    cv2.rectangle(roi_color,(ex,ey),(ex+ew,ey+eh),(0,255,0),2)\n",
    "    #if len(faces)>0: #current_face:\n",
    "    #    os.system('nircmd.exe win max class \"IEFrame\"')\n",
    "        #time.sleep(5) \n",
    "    #elif len(faces)==1:\n",
    "        #os.system('exit')\n",
    "    \n",
    "    current_face= len(faces)\n",
    "    \n",
    "    cv2.imshow(\"Faces found\" ,frame)\n",
    "    #cv2.imshow(\"Camera\" ,frame)\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "        \n",
    "# When everything done, release the capture\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Useful os command for next step :)\n",
    "os.getcwd()\n",
    "os.system('nircmd.exe win min class \"IEFrame\"')"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
